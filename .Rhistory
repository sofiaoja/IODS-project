p1 <- ggplot(learning2014, aes(x = attitude, y = points, col = gender))
# define the visualization type (points)
p2 <- p1 + geom_point()
# draw the plot
p2
# add a regression line
p3 <- p2 + geom_smooth(method = "lm")
# add a main title and draw the plot
p4 <- p3 + ggtitle("Student's attitude versus exam points")
p4
# title: New R script file for Analysis created 310117
# author: Sofia Oja
# date: 31 tammikuuta 2017
# read the data into memory
learning2014 <- read.table("http://s3.amazonaws.com/assets.datacamp.com/production/course_2218/datasets/learning2014.txt", header=TRUE, sep=",")
# see the stucture of the new dataset
# learning2014 data set has 166 obs. of 7 variables: gender, Age, Attitude, deep, stra, surf, Points
str(learning2014)
head(learning2014)
dim(learning2014)
# access the GGally and ggplot2 libraries
library(GGally)
library(ggplot2)
# advanced plot matrix with ggpairs()
p <- ggpairs(learning2014, mapping = aes(), lower = list(combo = wrap("facethist", bins = 20)))
# draw the plot
p
# Parameters resembling normal distrubtion: Attitude, deep, stra, surf. Strong correlation between points and deep (0.437), surf and deep (-0.324), surf and stra (-0.161)
# print out a summary
summary(learning2014)
# create a regression model with multiple explanatory variables
my_model <- lm(points ~ attitude + stra + surf, data = learning2014)
# print out a summary of the model
summary(my_model)
# title: New R script file for Analysis created 310117
# author: Sofia Oja
# date: 31 tammikuuta 2017
# read the data into memory
learning2014 <- read.table("http://s3.amazonaws.com/assets.datacamp.com/production/course_2218/datasets/learning2014.txt", header=TRUE, sep=",")
# see the stucture of the new dataset
# learning2014 data set has 166 obs. of 7 variables: gender, Age, Attitude, deep, stra, surf, Points
str(learning2014)
head(learning2014)
dim(learning2014)
# access the GGally and ggplot2 libraries
library(GGally)
library(ggplot2)
# advanced plot matrix with ggpairs()
p <- ggpairs(learning2014, mapping = aes(), lower = list(combo = wrap("facethist", bins = 20)))
# draw the plot
# Parameters resembling normal distrubtion: Attitude, deep, stra, surf. Strong correlation between points and attitude (0.437), surf and deep (-0.324), surf and stra (-0.161)
p
# print out a summary
summary(learning2014)
# regression model with multiple explanatory variables
# Positive correlation between points and attitude (0.437), points and stra (0.146), negative correlation between points and surf (-0.144). To improve linear model surf parameter excluded.
#my_model <- lm(points ~ attitude + stra + surf, data = learning2014)
my_model <- lm(points ~ attitude + stra, data = learning2014)
# print out a summary of the model
summary(my_model)
# title: New R script file for Analysis created 310117
# author: Sofia Oja
# date: 31 tammikuuta 2017
# read the data into memory
learning2014 <- read.table("http://s3.amazonaws.com/assets.datacamp.com/production/course_2218/datasets/learning2014.txt", header=TRUE, sep=",")
# see the stucture of the new dataset
# learning2014 data set has 166 obs. of 7 variables: gender, Age, Attitude, deep, stra, surf, Points
str(learning2014)
head(learning2014)
dim(learning2014)
# access the GGally and ggplot2 libraries
library(GGally)
library(ggplot2)
# advanced plot matrix with ggpairs()
p <- ggpairs(learning2014, mapping = aes(), lower = list(combo = wrap("facethist", bins = 20)))
# draw the plot
# Parameters resembling normal distrubtion: Attitude, deep, stra, surf. Strong correlation between points and attitude (0.437), surf and deep (-0.324), surf and stra (-0.161)
p
# print out a summary
summary(learning2014)
# regression model with multiple explanatory variables
# Positive correlation between points and attitude (0.437), points and stra (0.146), negative correlation between points and surf (-0.144). To improve linear model surf parameter excluded.
#my_model <- lm(points ~ attitude + stra + surf, data = learning2014)
my_model <- lm(points ~ attitude + stra, data = learning2014)
# print out a summary of the model
# The relationship between the chosen explanatory variables and the target variable is statistically significant for variable attitude (‘***’ 0.001), and not for stra (‘.’ 0.1). Multiple R squared of the model is 0.2048, which is quite low thus linear model might not be optimal model for this data. (Ref Wikipedia: In statistics, the coefficient of multiple correlation is a measure of how well a given variable can be predicted using a linear function of a set of other variables).
summary(my_model)
# diagnostic plots using the plot() function. Residuals vs Fitted values, Normal QQ-plot and Residuals vs Leverage, plots 1, 2 and 5
par(mfrow = c(2,2))
plot(my_model, which = c(1,2,5))
# title: New R script file for Analysis created 310117
# author: Sofia Oja
# date: 31 tammikuuta 2017
# read the data into memory
learning2014 <- read.table("http://s3.amazonaws.com/assets.datacamp.com/production/course_2218/datasets/learning2014.txt", header=TRUE, sep=",")
# see the stucture of the new dataset
# learning2014 data set has 166 obs. of 7 variables: gender, Age, Attitude, deep, stra, surf, Points
str(learning2014)
head(learning2014)
dim(learning2014)
# access the GGally and ggplot2 libraries
library(GGally)
library(ggplot2)
# advanced plot matrix with ggpairs()
p <- ggpairs(learning2014, mapping = aes(), lower = list(combo = wrap("facethist", bins = 20)))
# draw the plot
# Parameters resembling normal distrubtion: Attitude, deep, stra, surf. Strong correlation between points and attitude (0.437), surf and deep (-0.324), surf and stra (-0.161)
p
# print out a summary
summary(learning2014)
# regression model with multiple explanatory variables
# Positive correlation between points and attitude (0.437), points and stra (0.146), negative correlation between points and surf (-0.144). To improve linear model surf parameter excluded.
#my_model <- lm(points ~ attitude + stra + surf, data = learning2014)
my_model <- lm(points ~ attitude + stra, data = learning2014)
# print out a summary of the model
# The relationship between the chosen explanatory variables and the target variable is statistically significant for variable attitude (‘***’ 0.001), and not for stra (‘.’ 0.1). Multiple R squared of the model is 0.2048, which is quite low thus linear model might not be optimal model for this data. (Ref Wikipedia: In statistics, the coefficient of multiple correlation is a measure of how well a given variable can be predicted using a linear function of a set of other variables).
summary(my_model)
# diagnostic plots using the plot() function. Residuals vs Fitted values, Normal QQ-plot and Residuals vs Leverage, plots 1, 2 and 5
# Some outliers seen from diagnostic plots, e.g. in Normal Q-Q plot data not linear in the beginnig and at the end points thus linear model might not be optimal model for this data.
par(mfrow = c(2,2))
plot(my_model, which = c(1,2,5))
# title: New R script file for Data Wrangling created 310117
# author: Sofia Oja
# date: 31 tammikuuta 2017
# read the data into memory
lrn14 <- read.table("http://www.helsinki.fi/~kvehkala/JYTmooc/JYTOPKYS3-data.txt", sep="\t", header=TRUE)
# the dimensions of the data
# output: [1] 183  60
dim(lrn14)
# the structure of the data
# output:
# 'data.frame':	183 obs. of  60 variables:
# $ Aa      : int  3 2 4 4 3 4 4 3 2 3 ...
# $ Ab      : int  1 2 1 2 2 2 1 1 1 2 ...
str(lrn14)
# access the dplyr library
library(dplyr)
# read the data into memory
#JYTOPKYS2 <- read.table("http://www.helsinki.fi/~kvehkala/JYTmooc/JYTOPKYS2-meta.txt", sep="\t", header=TRUE)
# questions related to deep, surface and strategic learning
deep_questions <- c("D03", "D11", "D19", "D27", "D07", "D14", "D22", "D30","D06",  "D15", "D23", "D31")
surface_questions <- c("SU02","SU10","SU18","SU26", "SU05","SU13","SU21","SU29","SU08","SU16","SU24","SU32")
strategic_questions <- c("ST01","ST09","ST17","ST25","ST04","ST12","ST20","ST28")
# columns related to deep learning and create column 'deep' by averaging
deep_columns <- select(lrn14, one_of(deep_questions))
lrn14$deep <- rowMeans(deep_columns)
# columns related to surface learning and create column 'surf' by averaging
surface_columns <- select(lrn14, one_of(surface_questions))
lrn14$surf <- rowMeans(surface_columns)
# columns related to strategic learning and create column 'stra' by averaging
strategic_columns <- select(lrn14, one_of(strategic_questions))
lrn14$stra <- rowMeans(strategic_columns)
# handful of columns to keep
keep_columns <- c("gender","Age","Attitude", "deep", "stra", "surf", "Points")
# 'keep_columns' to create a new dataset
learning2014 <- select(lrn14, one_of(keep_columns))
# rows where points is greater than zero
learning2014 <- filter(learning2014, Points > 0)
# see the stucture of the new dataset
str(learning2014)
# write CSV in R
write.csv(learning2014, file = "c:/Users/Sofia/Documents/Joni/R/data/learning2014.csv")
# read CSV into R
MyData <- read.csv(file="c:/Users/Sofia/Documents/Joni/R/data/learning2014.csv", header=TRUE, sep=",")
# stucture of the new dataset
str(MyData)
head(MyData)
lrn14 <- read.table("http://www.helsinki.fi/~kvehkala/JYTmooc/JYTOPKYS3-data.txt", sep="\t", header=TRUE)
dim(lrn14)
str(lrn14)
keep_columns <- c("gender","Age","attitude", "deep", "stra", "surf", "Points")
lrn14 <- read.table("http://www.helsinki.fi/~kvehkala/JYTmooc/JYTOPKYS2-meta.txt", sep="\t", header=TRUE)
keep_columns <- c("gender","Age","attitude", "deep", "stra", "surf", "Points")
learning2014 <- select(lrn14, one_of(keep_columns))
str(lrn14)
str(lrn14)
lrn14 <- read.table("http://www.helsinki.fi/~kvehkala/JYTmooc/JYTOPKYS3-data.txt", sep="\t", header=TRUE)
keep_columns <- c("gender","Age","attitude", "deep", "stra", "surf", "Points")
learning2014 <- filter(learning2014, points == 0)
learning2014 <- filter(learning2014, points = 0)
keep_columns <- c("gender","age","attitude", "deep", "stra", "surf", "points")
learning2014 <- filter(learning2014, points > 0)
lrn14<- filter(learning2014, points > 0)
str(lrn14)
keep_columns <- c("gender","age","attitude", "deep", "stra", "surf", "points")
str(lrn14)
keep_columns <- c("gender","Age","Attitude", "deep", "stra", "surf", "Point")
str(lrn14)
library(dplyr)
str(lrn14)
keep_columns <- c("gender","Age","Attitude", "deep", "stra", "surf", "Points")
library(dplyr)
keep_columns <- c("gender","Age","Attitude", "deep", "stra", "surf", "Points")
colnames(learning2014)[2] <- "age"
colnames(learning2014)[3] <- "attitude"
colnames(learning2014)[7] <- "points"
learning2014 <- filter(learning2014, points > 0)
str(lrn14)
dim(lrn14)
library(dplyr)
colnames(learning2014)[2] <- "age"
colnames(learning2014)[3] <- "attitude"
colnames(learning2014)[7] <- "points"
keep_columns <- c("gender","age","attitude", "deep", "stra", "surf", "points")
str(lrn14)
learning2014 <- filter(learning2014, points > 0)
dim(lrn14)
dim(learning2014)
keep_columns <- c("gender","age","attitude", "deep", "stra", "surf", "points")
learning2014 <- filter(learning2014, points > 0)
dim(learning2014)
?write.csv
# Sofia 020217 Regression and model validation excercise
# title: New R script file for Data Wrangling created 310117
# author: Sofia Oja
# date: 31 tammikuuta 2017
# read the data into memory
lrn14 <- read.table("http://www.helsinki.fi/~kvehkala/JYTmooc/JYTOPKYS3-data.txt", sep="\t", header=TRUE)
# the dimensions of the data
# output: [1] 183  60
dim(lrn14)
# the structure of the data
# output:
# 'data.frame':	183 obs. of  60 variables:
# $ Aa      : int  3 2 4 4 3 4 4 3 2 3 ...
# $ Ab      : int  1 2 1 2 2 2 1 1 1 2 ...
str(lrn14)
# access the dplyr library
library(dplyr)
# read the data into memory
#JYTOPKYS2 <- read.table("http://www.helsinki.fi/~kvehkala/JYTmooc/JYTOPKYS2-meta.txt", sep="\t", header=TRUE)
# questions related to deep, surface and strategic learning
deep_questions <- c("D03", "D11", "D19", "D27", "D07", "D14", "D22", "D30","D06",  "D15", "D23", "D31")
surface_questions <- c("SU02","SU10","SU18","SU26", "SU05","SU13","SU21","SU29","SU08","SU16","SU24","SU32")
strategic_questions <- c("ST01","ST09","ST17","ST25","ST04","ST12","ST20","ST28")
# columns related to deep learning and create column 'deep' by averaging
deep_columns <- select(lrn14, one_of(deep_questions))
lrn14$deep <- rowMeans(deep_columns)
# columns related to surface learning and create column 'surf' by averaging
surface_columns <- select(lrn14, one_of(surface_questions))
lrn14$surf <- rowMeans(surface_columns)
# columns related to strategic learning and create column 'stra' by averaging
strategic_columns <- select(lrn14, one_of(strategic_questions))
lrn14$stra <- rowMeans(strategic_columns)
# handful of columns to keep
keep_columns <- c("gender","Age","Attitude", "deep", "stra", "surf", "Points")
# 'keep_columns' to create a new dataset
learning2014 <- select(lrn14, one_of(keep_columns))
# rows where points is greater than zero
learning2014 <- filter(learning2014, Points > 0)
# see the stucture of the new dataset
str(learning2014)
# write CSV in R
write.csv(learning2014, file = "c:/Users/Sofia/Documents/Joni/R/data/learning2014.csv")
# read CSV into R
MyData <- read.csv(file="c:/Users/Sofia/Documents/Joni/R/data/learning2014.csv", header=TRUE, sep=",")
# stucture of the new dataset
str(MyData)
head(MyData)
# Sofia 020217 Regression and model validation excercise
# title: New R script file for Data Wrangling created 310117
# author: Sofia Oja
# date: 31 tammikuuta 2017
# read the data into memory
lrn14 <- read.table("http://www.helsinki.fi/~kvehkala/JYTmooc/JYTOPKYS3-data.txt", sep="\t", header=TRUE)
# the dimensions of the data
# output: [1] 183  60
dim(lrn14)
# the structure of the data
# output:
# 'data.frame':	183 obs. of  60 variables:
# $ Aa      : int  3 2 4 4 3 4 4 3 2 3 ...
# $ Ab      : int  1 2 1 2 2 2 1 1 1 2 ...
str(lrn14)
# access the dplyr library
library(dplyr)
# read the data into memory
#JYTOPKYS2 <- read.table("http://www.helsinki.fi/~kvehkala/JYTmooc/JYTOPKYS2-meta.txt", sep="\t", header=TRUE)
# questions related to deep, surface and strategic learning
deep_questions <- c("D03", "D11", "D19", "D27", "D07", "D14", "D22", "D30","D06",  "D15", "D23", "D31")
surface_questions <- c("SU02","SU10","SU18","SU26", "SU05","SU13","SU21","SU29","SU08","SU16","SU24","SU32")
strategic_questions <- c("ST01","ST09","ST17","ST25","ST04","ST12","ST20","ST28")
# columns related to deep learning and create column 'deep' by averaging
deep_columns <- select(lrn14, one_of(deep_questions))
lrn14$deep <- rowMeans(deep_columns)
# columns related to surface learning and create column 'surf' by averaging
surface_columns <- select(lrn14, one_of(surface_questions))
lrn14$surf <- rowMeans(surface_columns)
# columns related to strategic learning and create column 'stra' by averaging
strategic_columns <- select(lrn14, one_of(strategic_questions))
lrn14$stra <- rowMeans(strategic_columns)
# handful of columns to keep
keep_columns <- c("gender","Age","Attitude", "deep", "stra", "surf", "Points")
# 'keep_columns' to create a new dataset
learning2014 <- select(lrn14, one_of(keep_columns))
# rows where points is greater than zero
learning2014 <- filter(learning2014, Points > 0)
# see the stucture of the new dataset
str(learning2014)
# write CSV in R
write.csv(learning2014, file = "c:/Users/Sofia/Documents/Joni/R/data/learning2014.csv")
# read CSV into R
MyData <- read.csv(file="c:/Users/Sofia/Documents/Joni/R/data/learning2014.csv", header=TRUE, sep=",")
# stucture of the new dataset
str(MyData)
head(MyData)
# Sofia 020217 Regression and model validation excercise
# title: New R script file for Data Wrangling created 310117
# author: Sofia Oja
# date: 31 tammikuuta 2017
# read the data into memory
lrn14 <- read.table("http://www.helsinki.fi/~kvehkala/JYTmooc/JYTOPKYS3-data.txt", sep="\t", header=TRUE)
# the dimensions of the data
# output: [1] 183  60
dim(lrn14)
# the structure of the data
# output:
# 'data.frame':	183 obs. of  60 variables:
# $ Aa      : int  3 2 4 4 3 4 4 3 2 3 ...
# $ Ab      : int  1 2 1 2 2 2 1 1 1 2 ...
str(lrn14)
# access the dplyr library
library(dplyr)
# read the data into memory
#JYTOPKYS2 <- read.table("http://www.helsinki.fi/~kvehkala/JYTmooc/JYTOPKYS2-meta.txt", sep="\t", header=TRUE)
# questions related to deep, surface and strategic learning
deep_questions <- c("D03", "D11", "D19", "D27", "D07", "D14", "D22", "D30","D06",  "D15", "D23", "D31")
surface_questions <- c("SU02","SU10","SU18","SU26", "SU05","SU13","SU21","SU29","SU08","SU16","SU24","SU32")
strategic_questions <- c("ST01","ST09","ST17","ST25","ST04","ST12","ST20","ST28")
# columns related to deep learning and create column 'deep' by averaging
deep_columns <- select(lrn14, one_of(deep_questions))
lrn14$deep <- rowMeans(deep_columns)
# columns related to surface learning and create column 'surf' by averaging
surface_columns <- select(lrn14, one_of(surface_questions))
lrn14$surf <- rowMeans(surface_columns)
# columns related to strategic learning and create column 'stra' by averaging
strategic_columns <- select(lrn14, one_of(strategic_questions))
lrn14$stra <- rowMeans(strategic_columns)
# handful of columns to keep
keep_columns <- c("gender","Age","Attitude", "deep", "stra", "surf", "Points")
# 'keep_columns' to create a new dataset
learning2014 <- select(lrn14, one_of(keep_columns))
# rows where points is greater than zero
learning2014 <- filter(learning2014, Points > 0)
# see the stucture of the new dataset
str(learning2014)
# write CSV in R
write.csv(learning2014, file = "data/learning2014.csv")
# read CSV into R
MyData <- read.csv(file="data/learning2014.csv", header=TRUE, sep=",")
# stucture of the new dataset
str(MyData)
head(MyData)
setwd("~/GitHub/IODS-project")
# Sofia 020217 Regression and model validation excercise
# title: New R script file for Data Wrangling created 310117
# author: Sofia Oja
# date: 31 tammikuuta 2017
# read the data into memory
lrn14 <- read.table("http://www.helsinki.fi/~kvehkala/JYTmooc/JYTOPKYS3-data.txt", sep="\t", header=TRUE)
# the dimensions of the data
# output: [1] 183  60
dim(lrn14)
# the structure of the data
# output:
# 'data.frame':	183 obs. of  60 variables:
# $ Aa      : int  3 2 4 4 3 4 4 3 2 3 ...
# $ Ab      : int  1 2 1 2 2 2 1 1 1 2 ...
str(lrn14)
# access the dplyr library
library(dplyr)
# read the data into memory
#JYTOPKYS2 <- read.table("http://www.helsinki.fi/~kvehkala/JYTmooc/JYTOPKYS2-meta.txt", sep="\t", header=TRUE)
# questions related to deep, surface and strategic learning
deep_questions <- c("D03", "D11", "D19", "D27", "D07", "D14", "D22", "D30","D06",  "D15", "D23", "D31")
surface_questions <- c("SU02","SU10","SU18","SU26", "SU05","SU13","SU21","SU29","SU08","SU16","SU24","SU32")
strategic_questions <- c("ST01","ST09","ST17","ST25","ST04","ST12","ST20","ST28")
# columns related to deep learning and create column 'deep' by averaging
deep_columns <- select(lrn14, one_of(deep_questions))
lrn14$deep <- rowMeans(deep_columns)
# columns related to surface learning and create column 'surf' by averaging
surface_columns <- select(lrn14, one_of(surface_questions))
lrn14$surf <- rowMeans(surface_columns)
# columns related to strategic learning and create column 'stra' by averaging
strategic_columns <- select(lrn14, one_of(strategic_questions))
lrn14$stra <- rowMeans(strategic_columns)
# handful of columns to keep
keep_columns <- c("gender","Age","Attitude", "deep", "stra", "surf", "Points")
# 'keep_columns' to create a new dataset
learning2014 <- select(lrn14, one_of(keep_columns))
# rows where points is greater than zero
learning2014 <- filter(learning2014, Points > 0)
# see the stucture of the new dataset
str(learning2014)
# write CSV in R
write.csv(learning2014, file = "/data/learning2014.csv")
# read CSV into R
MyData <- read.csv(file="/data/learning2014.csv", header=TRUE, sep=",")
# stucture of the new dataset
str(MyData)
head(MyData)
# Sofia 020217 Regression and model validation excercise
# title: New R script file for Data Wrangling created 310117
# author: Sofia Oja
# date: 31 tammikuuta 2017
# read the data into memory
lrn14 <- read.table("http://www.helsinki.fi/~kvehkala/JYTmooc/JYTOPKYS3-data.txt", sep="\t", header=TRUE)
# the dimensions of the data
# output: [1] 183  60
dim(lrn14)
# the structure of the data
# output:
# 'data.frame':	183 obs. of  60 variables:
# $ Aa      : int  3 2 4 4 3 4 4 3 2 3 ...
# $ Ab      : int  1 2 1 2 2 2 1 1 1 2 ...
str(lrn14)
# access the dplyr library
library(dplyr)
# read the data into memory
#JYTOPKYS2 <- read.table("http://www.helsinki.fi/~kvehkala/JYTmooc/JYTOPKYS2-meta.txt", sep="\t", header=TRUE)
# questions related to deep, surface and strategic learning
deep_questions <- c("D03", "D11", "D19", "D27", "D07", "D14", "D22", "D30","D06",  "D15", "D23", "D31")
surface_questions <- c("SU02","SU10","SU18","SU26", "SU05","SU13","SU21","SU29","SU08","SU16","SU24","SU32")
strategic_questions <- c("ST01","ST09","ST17","ST25","ST04","ST12","ST20","ST28")
# columns related to deep learning and create column 'deep' by averaging
deep_columns <- select(lrn14, one_of(deep_questions))
lrn14$deep <- rowMeans(deep_columns)
# columns related to surface learning and create column 'surf' by averaging
surface_columns <- select(lrn14, one_of(surface_questions))
lrn14$surf <- rowMeans(surface_columns)
# columns related to strategic learning and create column 'stra' by averaging
strategic_columns <- select(lrn14, one_of(strategic_questions))
lrn14$stra <- rowMeans(strategic_columns)
# handful of columns to keep
keep_columns <- c("gender","Age","Attitude", "deep", "stra", "surf", "Points")
# 'keep_columns' to create a new dataset
learning2014 <- select(lrn14, one_of(keep_columns))
# rows where points is greater than zero
learning2014 <- filter(learning2014, Points > 0)
# see the stucture of the new dataset
str(learning2014)
# write CSV in R
write.csv(learning2014, file = "data/learning2014.csv")
# read CSV into R
MyData <- read.csv(file="data/learning2014.csv", header=TRUE, sep=",")
# stucture of the new dataset
str(MyData)
head(MyData)
# Sofia 020217 Regression and model validation excercise
# title: New R script file for Analysis created 310117
# author: Sofia Oja
# date: 31 tammikuuta 2017
# read the data into memory
learning2014 <- read.table("http://s3.amazonaws.com/assets.datacamp.com/production/course_2218/datasets/learning2014.txt", header=TRUE, sep=",")
# see the stucture of the new dataset
# learning2014 data set has 166 obs. of 7 variables: gender, Age, Attitude, deep, stra, surf, Points
str(learning2014)
head(learning2014)
dim(learning2014)
# access the GGally and ggplot2 libraries
library(GGally)
library(ggplot2)
# advanced plot matrix with ggpairs()
p <- ggpairs(learning2014, mapping = aes(), lower = list(combo = wrap("facethist", bins = 20)))
# draw the plot
# Parameters resembling normal distrubtion: Attitude, deep, stra, surf. Strong correlation between points and attitude (0.437), surf and deep (-0.324), surf and stra (-0.161)
p
# print out a summary
summary(learning2014)
# regression model with multiple explanatory variables
# Positive correlation between points and attitude (0.437), points and stra (0.146), negative correlation between points and surf (-0.144). To improve linear model surf parameter excluded.
#my_model <- lm(points ~ attitude + stra + surf, data = learning2014)
my_model <- lm(points ~ attitude + stra, data = learning2014)
# print out a summary of the model
# The relationship between the chosen explanatory variables and the target variable is statistically significant for variable attitude (‘***’ 0.001), and not for stra (‘.’ 0.1). Multiple R squared of the model is 0.2048, which is quite low thus linear model might not be optimal model for this data. (Ref Wikipedia: In statistics, the coefficient of multiple correlation is a measure of how well a given variable can be predicted using a linear function of a set of other variables).
summary(my_model)
# diagnostic plots using the plot() function. Residuals vs Fitted values, Normal QQ-plot and Residuals vs Leverage, plots 1, 2 and 5
# Some outliers seen from diagnostic plots, e.g. in Normal Q-Q plot data not linear in the beginnig and at the end points thus linear model might not be optimal model for this data.
par(mfrow = c(2,2))
plot(my_model, which = c(1,2,5))
# Sofia 020217 Regression and model validation excercise
# title: New R script file for Analysis created 310117
# author: Sofia Oja
# date: 31 tammikuuta 2017
# read the data into memory
learning2014 <- read.table("http://s3.amazonaws.com/assets.datacamp.com/production/course_2218/datasets/learning2014.txt", header=TRUE, sep=",")
# see the stucture of the new dataset
# learning2014 data set has 166 obs. of 7 variables: gender, Age, Attitude, deep, stra, surf, Points
str(learning2014)
head(learning2014)
dim(learning2014)
# access the GGally and ggplot2 libraries
library(GGally)
library(ggplot2)
# advanced plot matrix with ggpairs()
p <- ggpairs(learning2014, mapping = aes(), lower = list(combo = wrap("facethist", bins = 20)))
# draw the plot
# Parameters resembling normal distrubtion: Attitude, deep, stra, surf. Strong correlation between points and attitude (0.437), surf and deep (-0.324), surf and stra (-0.161)
p
# print out a summary
summary(learning2014)
# regression model with multiple explanatory variables
# Positive correlation between points and attitude (0.437), points and stra (0.146), negative correlation between points and surf (-0.144). To improve linear model surf parameter excluded.
#my_model <- lm(points ~ attitude + stra + surf, data = learning2014)
my_model <- lm(points ~ attitude + stra, data = learning2014)
# print out a summary of the model
# The relationship between the chosen explanatory variables and the target variable is statistically significant for variable attitude (‘***’ 0.001), and not for stra (‘.’ 0.1). Multiple R squared of the model is 0.2048, which is quite low thus linear model might not be optimal model for this data. (Ref Wikipedia: In statistics, the coefficient of multiple correlation is a measure of how well a given variable can be predicted using a linear function of a set of other variables).
summary(my_model)
# diagnostic plots using the plot() function. Residuals vs Fitted values, Normal QQ-plot and Residuals vs Leverage, plots 1, 2 and 5
# Some outliers seen from diagnostic plots, e.g. in Normal Q-Q plot data not linear in the beginnig and at the end points thus linear model might not be optimal model for this data.
par(mfrow = c(2,2))
plot(my_model, which = c(1,2,5))
